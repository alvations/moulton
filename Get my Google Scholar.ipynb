{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pyderman\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_chrome(headless=True):\n",
    "    path = pyderman.install(browser=pyderman.chrome)\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    options.headless = headless\n",
    "\n",
    "    driver = webdriver.Chrome(path, options=options)\n",
    "\n",
    "    # Sanity checks.\n",
    "    driver.get(\"http://www.python.org\")\n",
    "    assert \"Python\" in driver.title\n",
    "    return driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromedriver is already installed.\n"
     ]
    }
   ],
   "source": [
    "driver = open_chrome(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscholar_url = \"https://scholar.google.com/citations?user=qre6vl0AAAAJ&hl=en\"\n",
    "driver.get(gscholar_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    e = driver.find_element_by_xpath('//button[@id=\"gsc_bpf_more\"]')\n",
    "    e.click()\n",
    "    if e.get_attribute('disabled') == 'true':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A report on the DSL shared task 2014\n",
      "M Zampieri, L Tan, N Ljubešić, J Tiedemann\n",
      "Proceedings of the first workshop on applying NLP tools to similar languages …\n",
      "80 2014\n",
      "{'Authors': 'Marcos Zampieri, Liling Tan, Nikola Ljubešić, Jörg Tiedemann', 'Publication date': '2014/8', 'Conference': 'Proceedings of the first workshop on applying NLP tools to similar languages, varieties and dialects', 'Pages': '58-67', 'Description': 'This paper summarizes the methods, results and findings of the Discriminating between Similar Languages (DSL) shared task 2014. The shared task provided data from 13 different languages and varieties divided into 6 groups. Participants were required to train their systems to discriminate between languages on a training and development set containing 20,000 sentences from each language (closed submission) and/or any other dataset (open submission). One month later, a test set containing 1,000 unidentified instances per language was released for evaluation. The DSL shared task received 22 inscriptions and 8 final submissions. The best system obtained 95.7% average accuracy.', 'Total citations': 80}\n",
      "#######\n",
      "Overview of the DSL shared task 2015\n",
      "M Zampieri, L Tan, N Ljubešić, J Tiedemann, P Nakov\n",
      "Proceedings of the Joint Workshop on Language Technology for Closely Related …\n",
      "69 2015\n",
      "{'Authors': 'Marcos Zampieri, Liling Tan, Nikola Ljubešić, Jörg Tiedemann, Preslav Nakov', 'Publication date': '2015/9', 'Conference': 'Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects', 'Pages': '1-9', 'Description': 'We present the results of the 2nd edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the LT4VarDial’2015 workshop and focused on the identification of very similar languages and language varieties. Unlike in the 2014 edition, in 2015 we had an Others category with languages that were not seen on training. Moreover, we had two test datasets: one using the original texts (test set A), and one with named entities replaced by placeholders (test set B). Ten teams participated in the task, and the best-performing system achieved 95.54% average accuracy on test set A, and 94.01% on test set B.', 'Total citations': 69}\n",
      "#######\n",
      "Merging comparable data sources for the discrimination of similar languages: The dsl corpus collection\n",
      "L Tan, M Zampieri, N Ljubešic, J Tiedemann\n",
      "Proceedings of the 7th Workshop on Building and Using Comparable Corpora …\n",
      "65 2014\n",
      "{'Authors': 'Liling Tan, Marcos Zampieri, Nikola Ljubešic, Jörg Tiedemann', 'Publication date': '2014/5/26', 'Journal': 'Proceedings of the 7th Workshop on Building and Using Comparable Corpora (BUCC)', 'Pages': '11-15', 'Description': 'This paper presents the compilation of the DSL corpus collection created for the DSL (Discriminating Similar Languages) shared task to be held at the VarDial workshop at COLING 2014. The DSL corpus collection were merged from three comparable corpora to provide a suitable dataset for automatic classification to discriminate similar languages and language varieties. Along with the description of the DSL corpus collection we also present results of baseline discrimination experiments reporting performance of up to 87.4% accuracy.', 'Total citations': 65}\n",
      "#######\n",
      "Building and annotating the linguistically diverse NTU-MC (NTU-multilingual corpus)\n",
      "L Tan, F Bond\n",
      "Proceedings of the 25th Pacific Asia Conference on Language, Information and …\n",
      "45 2011\n",
      "{'Authors': 'Liling Tan, Francis Bond', 'Publication date': '2011/12', 'Conference': 'Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation', 'Pages': '362-371', 'Description': 'The NTU-MC compilation taps on the linguistic diversity of multilingual texts available within Singapore. The current version of NTU-MC contains 375,000 words (15,000 sentences) in 6 languages (English, Chinese, Japanese, Korean, Indonesian and Vietnamese) from 6 language families (Indo-European, Sino-Tibetan, Japonic, Korean as a language isolate, Austronesian and Austro-Asiatic). The NTU-MC is annotated with a layer of monolingual annotation (POS tags) and cross-lingual annotation (sentence-level alignments). The diverse language data and cross-lingual annotations provide valuable information on linguistic diversity for traditional linguistic research as well as natural language processing tasks. This paper describes the corpus compilation process with the evaluation of the monolingual and cross-lingual annotations of the corpus data. The corpus is available under the Creative Commons–Attribute 3.0 Unported license (CC by).', 'Total citations': 45}\n",
      "#######\n",
      "Pywsd: Python implementations of word sense disambiguation (wsd) technologies [software]\n",
      "L Tan\n",
      "https://github.com/alvations/pywsd\n",
      "28 2014\n",
      "{'Authors': 'Liling Tan', 'Publication date': '2014', 'Source': 'https://github.com/alvations/pywsd', 'Total citations': 28}\n",
      "#######\n",
      "Manawi: Using multi-word expressions and named entities to improve machine translation\n",
      "L Tan, S Pal\n",
      "Proceedings of the Ninth Workshop on Statistical Machine Translation, 201-206\n",
      "22 2014\n",
      "{'Authors': 'Liling Tan, Santanu Pal', 'Publication date': '2014/6', 'Conference': 'Proceedings of the Ninth Workshop on Statistical Machine Translation', 'Pages': '201-206', 'Description': 'We describe the Manawi1 () system submitted to the 2014 WMT translation shared task. We participated in the English-Hindi (EN-HI) and Hindi-English (HI-EN) language pair and achieved 0.792 for the Translation Error Rate (TER) score2 for EN-HI, the lowest among the competing systems. Our main innovations are (i) the usage of outputs from NLP tools, viz. billingual multi-word expression extractor and named-entity recognizer to improve SMT quality and (ii) the introduction of a novel filter method based on sentence-alignment features. The Manawi system showed the potential of improving translation quality by incorporating multiple NLP tools within the MT pipeline.', 'Total citations': 22}\n",
      "#######\n",
      "Usaar-wlv: Hypernym generation with deep neural nets\n",
      "L Tan, R Gupta, J Van Genabith\n",
      "SemEval-2015, 932\n",
      "18 2015\n",
      "{'Authors': 'Liling Tan, Rohit Gupta, Josef Van Genabith', 'Publication date': '2015/6/4', 'Journal': 'SemEval-2015', 'Pages': '932', 'Description': 'This paper describes the USAAR-WLV taxonomy induction system that participated in the Taxonomy Extraction Evaluation task of SemEval-2015. We extend prior work on using vector space word embedding models for hypernym-hyponym extraction by simplifying the means to extract a projection matrix that transforms any hyponym to its hypernym. This is done by making use of function words, which are usually overlooked in vector space approaches to NLP. Our system performs best in the chemical domain and has achieved competitive results in the overall evaluations.', 'Total citations': 18}\n",
      "#######\n",
      "Usaar at semeval-2016 task 13: Hyponym endocentricity\n",
      "L Tan, F Bond, J van Genabith\n",
      "Proceedings of the 10th International Workshop on Semantic Evaluation …\n",
      "14 2016\n",
      "{'Authors': 'Liling Tan, Francis Bond, Josef van Genabith', 'Publication date': '2016/6', 'Conference': 'Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)', 'Pages': '1303-1309', 'Description': 'This paper describes our submission to the SemEval-2016 Taxonomy Extraction Evaluation (TExEval-2) Task. We examine the endocentric nature of hyponyms and propose a simple rule-based method to identify hypernyms at high precision. For the food domain, we extract lists of terms from the Wikipedia lists of lists by using the name of each list as the endocentric head and treating all terms in the extracted tables as the hyponym of the endocentric head.', 'Total citations': 14}\n",
      "#######\n",
      "Predicting machine translation adequacy with document embeddings\n",
      "M Vela, L Tan\n",
      "Proceedings of the Tenth Workshop on Statistical Machine Translation, 402-410\n",
      "12 2015\n",
      "{'Authors': 'Mihaela Vela, Liling Tan', 'Publication date': '2015/9', 'Conference': 'Proceedings of the Tenth Workshop on Statistical Machine Translation', 'Pages': '402-410', 'Description': 'This paper describes USAAR’s submission to the the metrics shared task of the Workshop on Statistical Machine Translation (WMT) in 2015. The goal of our submission is to take advantage of the semantic overlap between hypothesis and reference translation for predicting MT output adequacy using language independent document embeddings. The approach presented here is learning a Bayesian Ridge Regressor using document skip-gram embeddings in order to automatically evaluate Machine Translation (MT) output by predicting semantic adequacy scores. The evaluation of our submission–measured by the correlation with human judgements–shows promising results on system-level scores.', 'Total citations': 12}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Grammatical error detection with limited training data: The case of chinese\n",
      "M Zampieri, L Tan\n",
      "Proceedings of ICCE\n",
      "10 2014\n",
      "{'Authors': 'Marcos Zampieri, Liling Tan', 'Publication date': '2014/11/30', 'Journal': 'Proceedings of ICCE', 'Description': 'In this paper, we describe the UDS submission to the shared task on Grammatical Error Diagnosis for Learning Chinese as a Foreign Language. We designed four different experiments (runs) to approach this task. All of them are variations of a frequency-based approach using a journalistic corpus as standard corpus and comparing n-gram frequency lists to both the training and the test corpus provided by the shared task organizers. The assumption behind this approach is that comparing a standard reference corpus to a non-standard study corpus using frequency-based methods levels out non-standard features present in the study corpus. These features are very likely to be, in the case of this corpus, grammatical errors. Our system obtained 60.3% f-measure at the error detection level and 25.3% f-measure at the error diagnosis level.', 'Total citations': 10}\n",
      "#######\n",
      "Usaar-sheffield: Semantic textual similarity with deep regression and machine translation evaluation metrics\n",
      "L Tan, C Scarton, L Specia, J van Genabith\n",
      "Proceedings of the 9th international workshop on semantic evaluation …\n",
      "9 2015\n",
      "{'Authors': 'Liling Tan, Carolina Scarton, Lucia Specia, Josef van Genabith', 'Publication date': '2015', 'Journal': 'Proceedings of the 9th international workshop on semantic evaluation (SemEval 2015)', 'Pages': '85-89', 'Description': 'This paper describes the USAARSHEFFIELD systems that participated in the Semantic Textual Similarity (STS) English task of SemEval-2015. We extend the work on using machine translation evaluation metrics in the STS task. Different from previous approaches, we regard the metrics’ robustness across different text types and conflate the training data across different subcorpora. In addition, we introduce a novel deep regressor architecture and evaluated its efficiency in the STS task.', 'Total citations': 9}\n",
      "#######\n",
      "Seedling: Building and using a seed corpus for the human language project\n",
      "G Emerson, L Tan, S Fertmann, A Palmer, M Regneri\n",
      "Proceedings of the 2014 Workshop on the Use of Computational Methods in the …\n",
      "9 2014\n",
      "{'Authors': 'Guy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer, Michaela Regneri', 'Publication date': '2014/6', 'Conference': 'Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages', 'Pages': '77-85', 'Description': 'A broad-coverage corpus such as the Human Language Project envisioned by Abney and Bird (2010) would be a powerful resource for the study of endangered languages. Existing corpora are limited in the range of languages covered, in standardisation, or in machine-readability. In this paper we present SeedLing, a seed corpus for the Human Language Project. We first survey existing efforts to compile cross-linguistic resources, then describe our own approach. To build the foundation text for a Universal Corpus, we crawl and clean texts from several web sources that contain data from a large number of languages, and convert them into a standardised form consistent with the guidelines of Abney and Bird (2011). The resulting corpus is more easily-accessible and machine-readable than any of the underlying data sources, and, with data from 1451 languages covering 105 language families, represents a significant base corpus for researchers to draw on and add to in the future. To demonstrate the utility of SeedLing for cross-lingual computational research, we use our data in the test application of detecting similar languages.', 'Total citations': 9}\n",
      "#######\n",
      "Xling: Matching query sentences to a parallel corpus using topic models for wsd\n",
      "L Tan, F Bond\n",
      "Second Joint Conference on Lexical and Computational Semantics (* SEM …\n",
      "9 2013\n",
      "{'Authors': 'Liling Tan, Francis Bond', 'Publication date': '2013/6', 'Conference': 'Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)', 'Pages': '167-170', 'Description': 'This paper describes the XLING system participation in SemEval-2013 Crosslingual Word Sense Disambiguation task. The XLING system introduces a novel approach to skip the sense disambiguation step by matching query sentences to sentences in a parallel corpus using topic models; it returns the word alignments as the translation for the target polysemous words. Although, the topic-model base matching underperformed, the matching approach showed potential in the simple cosine-based surface similarity matching.', 'Total citations': 9}\n",
      "#######\n",
      "NTU-MC toolkit: Annotating a linguistically diverse corpus\n",
      "L Tan, F Bond\n",
      "Proceedings of COLING 2014, the 25th International Conference on …\n",
      "7 2014\n",
      "{'Authors': 'Liling Tan, Francis Bond', 'Publication date': '2014/8', 'Conference': 'Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations', 'Pages': '86-89', 'Description': 'The NTU-MC Toolkit is a compilation of tools to annotate the Nanyang Technological University-Multilingual Corpus (NTU-MC). The NTU-MC is a parallel corpora of linguistically diverse languages (Arabic, English, Indonesian, Japanese, Korean, Mandarin Chinese, Thai and Vietnamese). The NTU-MC thrives on the mantra of\" more data is better data and more annotation is better information\". Other than increasing parallel data from diverse language pairs, annotating the corpus with various layers of information allows corpora linguists to discover linguistic phenomena and provides computational linguists with pre-annotated features for various NLP tasks. In addition to the agglomeration existing tools into a single python wrapper library, we have implemented three tools (Mini-segmenter, GaChalign and Indotag) that (i) provides users with varying analysis of the corpus,(ii) improves the state-of-art performance and (iii) reimplements a previously unavailable annotation tool as a free and open tool. This paper briefly describes the wrapper classes available in the toolkit and introduces and demonstrates the usage of the Mini-segmenter, GaChalign and Indotag.', 'Total citations': 7}\n",
      "#######\n",
      "Examining crosslingual word sense disambiguation\n",
      "L Tan\n",
      "Nanyang Technological University, Nanyang Avenue\n",
      "7 2013\n",
      "{'Authors': 'Liling Tan', 'Publication date': '2013', 'Journal': 'Nanyang Technological University, Nanyang Avenue', 'Description': \"Understanding human language computationally remains a challenge at different levels, phonologically, syntactically and semantically. This thesis attempts to understand human language's ambiguity through the Word Sense Disambiguation (WSD) task. Word Sense Disambiguation (WSD) is the task of determining the correct sense of a word given a context sentence and topic models are statistical models of human language that can discover abstract topics given a collection of documents.\\nThis thesis examines the WSD task in a crosslingual manner with the usage of topic models and parallel corpus. The thesis defines a topical crosslingual WSD (Topical CLWSD) task as two subtasks (i) Match and Translate: finding a match of the query sentence in a parallel corpus using topic models that provides the appropriate translation of the target polysemous word (ii) Map: mapping the word-translation pair to disambiguate the concept respectively of the Open Multilingual WordNet. The XLING WSD system has been built to attempt the topical WSD task. Although the XLING system underperforms in the topical WSD task, it serves as a pilot approach to crosslingual WSD in a knowledge-lean manner.\", 'Total citations': 7}\n",
      "#######\n",
      "USHEF and USAAR-USHEF participation in the WMT15 QE shared task\n",
      "C Scarton, L Tan, L Specia\n",
      "Proceedings of the Tenth Workshop on Statistical Machine Translation, 336-341\n",
      "6 2015\n",
      "{'Authors': 'Carolina Scarton, Liling Tan, Lucia Specia', 'Publication date': '2015/9', 'Conference': 'Proceedings of the Tenth Workshop on Statistical Machine Translation', 'Pages': '336-341', 'Description': 'We present the results of the USHEF and USAAR-USHEF submissions for the WMT15 shared task on document-level quality estimation. The USHEF submissions explored several document and discourse-aware features. The USAARUSHEF submissions used an exhaustive search approach to select the best features from the official baseline. Results show slight improvements over the baseline with the use of discourse features. More interestingly, we found that a model of comparable performance can be built with only three features selected by the exhaustive search procedure.', 'Total citations': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Passive and pervasive use of a bilingual dictionary in statistical machine translation\n",
      "L Tan, J van Genabith, F Bond\n",
      "6 2015\n",
      "{'Authors': 'Liling Tan, Josef van Genabith, Francis Bond', 'Publication date': '2015/7/1', 'Description': 'There are two primary approaches to the use bilingual dictionary in statistical machine translation: (i) the passive approach of appending the parallel training data with a bilingual dictionary and (ii) the pervasive approach of enforcing translation as per the dictionary entries when decoding. Previous studies have shown that both approaches provide external lexical knowledge to statistical machine translation thus improving translation quality. We empirically investigate the effects of both approaches on the same dataset and provide further insights on how lexical information can be reinforced in statistical machine translation.', 'Total citations': 6}\n",
      "#######\n",
      "An Awkward Disparity between BLEU/RIBES and Human Judgment in Machine Translation\n",
      "L Tan, J Dehdari, J van Genebith\n",
      "6\n",
      "*\n",
      "2015\n",
      "{'Authors': 'Liling Tan, Jon Dehdari, Josef van Genebith', 'Publication date': '2015', 'Description': '• There’s always a bone to pick on MT evaluation metrics (Babych and Hartley, 2004; Callison-Burch et al. 2006; Smith et al. 2014; Graham et al. 2015)', 'Total citations': 6}\n",
      "#######\n",
      "Bira: Improved predictive exchange word clustering\n",
      "J Dehdari, L Tan, J van Genabith\n",
      "Proceedings of the 2016 Conference of the North American Chapter of the …\n",
      "5 2016\n",
      "{'Authors': 'Jon Dehdari, Liling Tan, Josef van Genabith', 'Publication date': '2016/6', 'Conference': 'Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies', 'Pages': '1169-1174', 'Description': 'Word clusters are useful for many NLP tasks including training neural network language models, but current increases in datasets are outpacing the ability of word clusterers to handle them. Little attention has been paid thus far on inducing high-quality word clusters at a large scale. The predictive exchange algorithm is quite scalable, but sometimes does not provide as good perplexity as other slower clustering algorithms.\\nWe introduce the bidirectional, interpolated, refining, and alternating (BIRA) predictive exchange algorithm. It improves upon the predictive exchange algorithm’s perplexity by up to 18%, giving it perplexities comparable to the slower two-sided exchange algorithm, and better perplexities than the slower Brown clustering algorithm. Our BIRA implementation is fast, clustering a 2.5 billion token English News Crawl corpus in 3 hours. It also reduces machine translation training time while preserving translation quality. Our implementation is portable and freely available.', 'Total citations': 5}\n",
      "#######\n",
      "Usaar-chronos: Crawling the web for temporal annotations\n",
      "L Tan, N Ordan\n",
      "Proceedings of the 9th International Workshop on Semantic Evaluation …\n",
      "5 2015\n",
      "{'Authors': 'Liling Tan, Noam Ordan', 'Publication date': '2015', 'Journal': 'Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)', 'Pages': '846-850', 'Description': 'This paper describes the USAAR-CHRONOS participation in the Diachronic Text Evaluation task of SemEval-2015 to identify the time period of historical text snippets. We adapt a web crawler to retrieve the original source of the text snippets and determine the publication year of the retrieved texts from their URLs. We report a precision score of> 90% in identifying the text epoch. Additionally, by crawling and cleaning the website that hosts the source of the text snippets, we present Daikon, a corpus that can be used for future work on epoch identification from a diachronic perspective.', 'Total citations': 5}\n",
      "#######\n",
      "Manipulating input data in machine translation\n",
      "L Tan, F Bond\n",
      "Proceedings of the 1st Workshop on Asian Translation (WAT2014)\n",
      "5 2014\n",
      "{'Authors': 'Liling Tan, Francis Bond', 'Publication date': '2014', 'Journal': 'Proceedings of the 1st Workshop on Asian Translation (WAT2014)', 'Description': 'Page 1. Manipulating Input Data for Machine Translation Liling Tan and Francis Bond Universität\\ndes Saarlandes and Nanyang Technological University alvations@gmail.com and\\nbond@ieee.org Introduction •Data quality/quantity affects MT easily •Whathappensifwetrytoremove,\\naddorrearrange input data? Approaches •Context sensitive data selection •Paraphrase data\\nextension •Lexicon addition •Character level MT (JP-ZH) Context Sensitive Data Selection\\n•Medical domain made up the majority of the ASPEC corpus (~ %) •Build separate model for\\nmedical text •Use generic model to decode the rest Paraphrase Data Extension •Generate EN\\nparaphrases with ERG and ACE (Flickinger, ) •Append EN paraphrases with original JP EN Input:\\nThe particle sizes of the products decreased as the amount of seed increased. Paraphrase: As\\nthe amount of seed increased, the particle sizes of the products decreased\\xa0… \\n', 'Total citations': 5}\n",
      "#######\n",
      "Usaar at semeval-2016 task 11: Complex word identification with sense entropy and sentence perplexity\n",
      "JMM Martínez, L Tan\n",
      "Proceedings of the 10th International Workshop on Semantic Evaluation …\n",
      "4 2016\n",
      "{'Authors': 'José Manuel Martínez Martínez, Liling Tan', 'Publication date': '2016/6', 'Conference': 'Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)', 'Pages': '958-962', 'Description': 'This paper describes an information-theoretic approach to complex word identification using a classifier based on an entropy based measure based on word senses and sentence-level perplexity features. We describe the motivation behind these features based on information density and demonstrate that they perform modestly well in the complex word identification task in SemEval-2016. We also discuss the possible improvements that can be made to future work by exploring the subjectivity of word complexity and more robust evaluation metrics for the complex word identification task.', 'Total citations': 4}\n",
      "#######\n",
      "Sensible: L2 translation assistance by emulating the manual post-editing process\n",
      "L Tan, A Schumann, J Martinez, F Bond\n",
      "Proceedings of the 8th International Workshop on Semantic Evaluation …\n",
      "4 2014\n",
      "{'Authors': 'Liling Tan, Anne Schumann, Jose Martinez, Francis Bond', 'Publication date': '2014/8', 'Conference': 'Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)', 'Pages': '541-545', 'Description': 'This paper describes the Post-Editor Z system submitted to the L2 writing assistant task in SemEval-2014. The aim of task is to build a translation assistance system to translate untranslated sentence fragments. This is not unlike the task of post-editing where human translators improve machine-generated translations. Post-Editor Z emulates the manual process of post-editing by (i) crawling and extracting parallel sentences that contain the untranslated fragments from a Web-based translation memory,(ii) extracting the possible translations of the fragments indexed by the translation memory and (iii) applying simple cosine-based sentence similarity to rank possible translations for the untranslated fragment.', 'Total citations': 4}\n",
      "#######\n",
      "Don’t Classify, Translate: Multi-Level E-Commerce Product Categorization Via Machine Translation\n",
      "MY Li, S Kok, L Tan\n",
      "Workshop on Information Technologies and Systems\n",
      "3 2018\n",
      "{'Authors': 'Maggie Yundi Li, Stanley Kok, Liling Tan', 'Publication date': '2018', 'Conference': 'Workshop on Information Technologies and Systems', 'Description': \"E-commerce platforms categorize their products into a multi-level taxonomy tree with thousands of leaf categories. Conventional methods for product categorization are typically based on machine learning classification algorithms. These algorithms take product information as input (eg, titles and descriptions) to classify a product into a leaf category. In this paper, we propose a new paradigm based on machine translation. In our approach, we translate a product's natural language description into a sequence of tokens representing a root-to-leaf path in a product taxonomy. In our experiments on two large real-world datasets, we show that our approach achieves better predictive accuracy than a state-of-the-art classification system for product categorization. In addition, we demonstrate that our machine translation models can propose meaningful new paths between previously unconnected nodes in a taxonomy tree, thereby transforming the taxonomy into a directed acyclic graph (DAG). We discuss how the resultant taxonomy DAG promotes user-friendly navigation, and how it is more adaptable to new products.\\nSubjects: Computation and Language (cs. CL); Machine Learning (cs. LG)\\nJournal reference: Workshop on Information Technologies and Systems 2018 (WITS2018)\\nCite as: arXiv: 1812.05774 [cs. CL]\\n(or arXiv: 1812.05774 v1 [cs. CL] for this version)\\nSubmission history\\nFrom: Liling Tan [view email]\\n[v1] Fri, 14 Dec 2018 04: 12: 02 UTC (3,960 KB)\", 'Total citations': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Saarsheff at semeval-2016 task 1: semantic textual similarity with machine translation evaluation metrics and (extreme) boosted tree ensembles\n",
      "L Tan, C Scarton, L Specia, J van Genabith\n",
      "Proceedings of the 10th International Workshop on Semantic Evaluation …\n",
      "3 2016\n",
      "{'Authors': 'Liling Tan, Carolina Scarton, Lucia Specia, Josef van Genabith', 'Publication date': '2016/6', 'Conference': 'Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)', 'Pages': '628-633', 'Description': 'This paper describes the SAARSHEFF systems that participated in the English Semantic Textual Similarity (STS) task in SemEval-2016. We extend the work on using machine translation (MT) metrics in the STS task by automatically annotating the STS datasets with a variety of MT scores for each pair of text snippets in the STS datasets. We trained our systems using boosted tree ensembles and achieved competitive results that outperforms he median Pearson correlation scores from all participating systems.', 'Total citations': 3}\n",
      "#######\n",
      "Wolvesaar at semeval-2016 task 1: Replicating the success of monolingual word alignment and neural embeddings for semantic textual similarity\n",
      "H Bechara, R Gupta, L Tan, C Orasan, R Mitkov, J van Genabith\n",
      "Proceedings of the 10th International Workshop on Semantic Evaluation …\n",
      "3 2016\n",
      "{'Authors': 'Hannah Bechara, Rohit Gupta, Liling Tan, Constantin Orasan, Ruslan Mitkov, Josef van Genabith', 'Publication date': '2016', 'Journal': 'Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)', 'Pages': '634-639', 'Description': 'This paper describes the WOLVESAAR systems that participated in the English Semantic Textual Similarity (STS) task in SemEval-2016. We replicated the top systems from the last two editions of the STS task and extended the model using GloVe word embeddings and dense vector space LSTM based sentence representations. We compared the difference in performance of the replicated system and the extended variants. Our variants to the replicated system show improved correlation scores and all of our submissions outperform the median scores from all participating systems.', 'Total citations': 3}\n",
      "#######\n",
      "Scaling Up Word Clustering\n",
      "J Dehdari, L Tan, J van Genabith\n",
      "3 2016\n",
      "{'Authors': 'Jon Dehdari, Liling Tan, Josef van Genabith', 'Publication date': '2016', 'Description': 'Word clusters improve performance in many NLP tasks including training neural network language models, but current increases in datasets are outpacing the ability of word clusterers to handle them. In this paper we present a novel bidirectional, interpolated, refining, and alternating (BIRA) predictive exchange algorithm and introduce ClusterCat, a clusterer based on this algorithm. We show that ClusterCat is 3–85 times faster than four other well-known clusterers, while also improving upon the predictive exchange algorithm’s perplexity by up to 18%. Notably, ClusterCat clusters a 2.5 billion token English News Crawl corpus in 3 hours. We also evaluate in a machine translation setting, resulting in shorter training times achieving the same translation quality measured in BLEU scores. ClusterCat is portable and freely available.', 'Total citations': 3}\n",
      "#######\n",
      "MacSaar at SemEval-2016 Task 11: Zipfian and Character Features for Complex Word Identification\n",
      "M Zampieri, L Tan, J van Genabith\n",
      "3 2016\n",
      "{'Authors': 'Marcos Zampieri, Liling Tan, Josef van Genabith', 'Publication date': '2016', 'Description': 'This paper presents the MacSaar system developed to identify complex words in English texts. MacSaar participated in the SemEval 2016 task 11: Complex Word Identification submitting two runs. The system is based on the assumption that complex words are likely to be less frequent and on average longer than words considered to be simple. We report results of 82.5% accuracy and 27% F-Score using a Random Forest Classifier. The best Mac-Saar submission was ranked 8th in terms of F-Measure among 45 entries.', 'Total citations': 3}\n",
      "#######\n",
      "The OPT-ional phenomenon in Singapore English: A corpus-based approach using time annotated corpora\n",
      "EYM Lai, L Tan, V Wong, LTT Loke, F Bond\n",
      "Procedia-Social and Behavioral Sciences 95, 431-441\n",
      "3 2013\n",
      "{'Authors': 'Eric Yong Ming Lai, Liling Tan, Vincent Wong, Lenny Teng Tao Loke, Francis Bond', 'Publication date': '2013/10/25', 'Journal': 'Procedia-Social and Behavioral Sciences', 'Volume': '95', 'Pages': '431-441', 'Publisher': 'Elsevier', 'Description': 'The Optional Omission of Past Tense (OPT) is prevalent in the colloquial register of Singapore English (SCE). This paper describes the investigation of the OPT phenomenon based on time annotated corpora. The Singapore and Hong Kong version of the International Corpus of English were extended with time annotation for this study. In Singapore English sentences that contain the perfective aspectual adverbs of already or yesterday, the OPT-ional phenomenon is found to be present 68.2% of the time. Although this phenomenon is also found in Hong Kong English, it is significantly more prominent in Singapore English (p<0.05, z=6.27). In SCE, there are also syntactic constraints that influence the OPT occurrences, where the omission of past tense occurs 39.8% more frequently in sentences with pre-verbal adverbs than post-verbal adverbs.', 'Total citations': 3}\n",
      "#######\n",
      "Unconstrained Product Categorization with Sequence-to-Sequence Models\n",
      "MY Li, L Tan, S Kok, E Szymanska\n",
      "1 2018\n",
      "{'Authors': 'Maggie Yundi Li, Liling Tan, Stanley Kok, Ewa Szymanska', 'Publication date': '2018', 'Description': 'Product categorization is a critical component of e-commerce platforms that enables organization and retrieval of the relevant products. Instead of following the conventional classification approaches, we consider category prediction as a sequence generation task where we allow product categorization beyond the hierarchical definition of the full taxonomy.\\nThis paper presents our submissions for the Rakuten Data Challenge at SIGIR eCom’18. The goal of the challenge is to predict the multi-level hierarchical product categories given the e-commerce product titles. We ensembled several attentional sequence-to-sequence models to generate product category labels without supervised constraints. Such unconstrained product categorization suggests possible addition to the existing category hierarchy and reveals ambiguous and repetitive category leaves. Our system achieved a balanced F-score of 0.8256, while the organizers’ baseline system scored 0.8142, and the best performing system scored 0.8513.', 'Total citations': 1}\n",
      "#######\n",
      "Faster and lighter phrase-based machine translation baseline\n",
      "L Tan\n",
      "Proceedings of the 3rd Workshop on Asian Translation (WAT2016), 184-193\n",
      "1 2016\n",
      "{'Authors': 'Liling Tan', 'Publication date': '2016/12', 'Conference': 'Proceedings of the 3rd Workshop on Asian Translation (WAT2016)', 'Pages': '184-193', 'Description': 'This paper describes the SENSE machine translation system participation in the Third Workshop for Asian Translation (WAT2016). We share our best practices to build a fast and light phrase-based machine translation (PBMT) models that have comparable results to the baseline systems provided by the organizers. As Neural Machine Translation (NMT) overtakes PBMT as the state-of-the-art, deep learning and new MT practitioners might not be familiar with the PBMT paradigm and we hope that this paper will help them build a PBMT baseline system quickly and easily.', 'Total citations': 1}\n",
      "#######\n",
      "D4. 2: Terminology and ontology\n",
      "L Tan, J van Genabith, M Zampieri, A Schumann, J Dehdari, S Pal\n",
      "Technical report, EXPERT (EXPloiting Empirical appRoaches to Translation …\n",
      "1 2015\n",
      "{'Authors': 'Liling Tan, Josef van Genabith, Marcos Zampieri, Anne Schumann, Jon Dehdari, Santanu Pal', 'Publication date': '2015', 'Publisher': 'Technical report, EXPERT (EXPloiting Empirical appRoaches to Translation) Consortium', 'Description': 'This document reports the advancement in terminology extraction and ontology induction research carried out in Work Package 4.2 (WP4. 2) by Early Stage Researcher 5 (ESR5) under the EXPERT (EXPloiting Empirical appRoaches to Translation) project. The report is split into two parts and an overall conclusion; the first part will describe the experiments on term extraction (Sections 2-4) and the second on ontology induction (Sections 5-7).', 'Total citations': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "Sarah’s Participation in WAT 2019\n",
      "RH Susanto, O Htun, L Tan\n",
      "Proceedings of the 6th Workshop on Asian Translation, 152-158\n",
      "2019\n",
      "{'Authors': 'Raymond Hendy Susanto, Ohnmar Htun, Liling Tan', 'Publication date': '2019/11', 'Conference': 'Proceedings of the 6th Workshop on Asian Translation', 'Pages': '152-158', 'Description': 'This paper describes our MT systems’ participation in the of WAT 2019. We participated in the (i) Patent,(ii) Timely Disclosure,(iii) Newswire and (iv) Mixed-domain tasks. Our main focus is to explore how similar Transformer models perform on various tasks. We observed that for tasks with smaller datasets, our best model setup are shallower models with lesser number of attention heads. We investigated practical issues in NMT that often appear in production settings, such as coping with multilinguality and simplifying pre-and post-processing pipeline in deployment.'}\n",
      "#######\n",
      "Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)\n",
      "P Nakov, M Zampieri, L Tan, N Ljubešić, J Tiedemann, S Malmasi\n",
      "Proceedings of the Third Workshop on NLP for Similar Languages, Varieties …\n",
      "2016\n",
      "{'Authors': 'Preslav Nakov, Marcos Zampieri, Liling Tan, Nikola Ljubešić, Jörg Tiedemann, Shervin Malmasi', 'Publication date': '2016', 'Journal': 'Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)', 'Description': 'VarDial is a well-established series of workshops, attracting researchers working on a range of topics related to the study of linguistic variation, eg, on building language resources for language varieties and dialects or in creating language technology and applications that make use of language closeness and exploit existing resources in a related language or a language variant.\\nThe research presented in the two previous editions, namely VarDial’2014, which was co-located with COLING’2014, and LT4VarDial’2015, which was held together with RANLP’2015, focused on topics such as machine translation between closely related languages, adaptation of POS taggers and parsers for similar languages and language varieties, compilation of corpora for language varieties, spelling normalization, and finally discrimination between and identification of similar languages. The latter was also the topic of the DSL shared task, held in conjunction with the workshop.'}\n",
      "#######\n",
      "Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects\n",
      "P Nakov, M Zampieri, P Osenova, L Tan, C Vertan, N Ljubešić, ...\n",
      "Proceedings of the Joint Workshop on Language Technology for Closely Related …\n",
      "2015\n",
      "{'Authors': 'Preslav Nakov, Marcos Zampieri, Petya Osenova, Liling Tan, Cristina Vertan, Nikola Ljubešić, Jörg Tiedemann', 'Publication date': '2015', 'Journal': 'Proceedings of the Joint Workshop on Language Technology for Closely Related Languages, Varieties and Dialects', 'Description': 'A large number of closely related language varieties and dialects are in daily use, not only as spoken colloquial languages but also in some written media, eg, in SMS, chats, and social networks. Language resources for these varieties and dialects are sparse and building them could be very labor intensive. Yet, these efforts can often be reduced by making use of pre-existing resources and tools for related, resource-richer languages.'}\n",
      "#######\n",
      "EXPERT Innovations in Terminology Extraction and Ontology Induction\n",
      "L Tan\n",
      "Hernani Costa, Anna Zaretskaya, Gloria Corpas Pastor, 45\n",
      "2015\n",
      "{'Authors': 'Liling Tan', 'Publication date': '2015', 'Journal': 'Hernani Costa, Anna Zaretskaya, Gloria Corpas Pastor', 'Pages': '45'}\n",
      "#######\n",
      "Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects\n",
      "M Zampieri, L Tan, N Ljubešić, J Tiedemann\n",
      "Proceedings of the First Workshop on Applying NLP Tools to Similar Languages …\n",
      "2014\n",
      "{'Authors': 'Marcos Zampieri, Liling Tan, Nikola Ljubešić, Jörg Tiedemann', 'Publication date': '2014', 'Journal': 'Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects', 'Description': 'The interest in language resources and computational models for the study of similar languages, varieties and dialects has been growing substantially in the last few years. The first edition of the Workshop on Applying NLP tools to similar languages, varieties and dialects (VarDial) confirms the interest in the topic.\\nWithin the NLP community, the impact of language variation in the development of language resources and NLP applications has been explored in recent years with experiments in different directions. For example, automatic classification or identification of closely related languages such as in Huang and Lee (2008) and Tiedemann and Ljubešic (2012); corpus-driven studies focusing on lexical variation between varieties such as the one by Piersman et al.(2010) or Ljubešic and Fišer (2013); and finally, the adaptation of language models in the context of machine translation such as in Nakov and Tiedemann (2012).'}\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "publications = []\n",
    "\n",
    "for e in driver.find_elements_by_xpath('//tr[@class=\"gsc_a_tr\"]'):\n",
    "    WebDriverWait(e, 20).until(EC.element_to_be_clickable((By.XPATH, \n",
    "        '//a[(@class=\"gsc_a_at\") and contains(text(), \"{}\")]'.format(e.text.split('\\n')[0])))).click()\n",
    "    _json = {}\n",
    "    ##time.sleep(0.7)\n",
    "    print(e.text)\n",
    "    bsoup = BeautifulSoup(driver.page_source.encode('utf-8'))\n",
    "    cite = bsoup.find('div', attrs={'id': 'gs_md_cita-l'})\n",
    "    keys = cite.find_all('div', attrs={'class':'gsc_vcd_field'})\n",
    "    values = cite.find_all('div', attrs={'class':'gsc_vcd_value'})\n",
    "    for k,v in zip(keys, values):\n",
    "        if k.text == 'Scholar articles':\n",
    "            continue\n",
    "        if k.text == 'Total citations':\n",
    "            _json[k.text] = int(v.find('a').text[9:])\n",
    "        else:\n",
    "            _json[k.text] = v.get_text('\\n')\n",
    "    ##print(_json)\n",
    "    time.sleep(0.7)\n",
    "    driver.find_element_by_xpath('//a[@id=\"gs_md_cita-d-x\"]').click()\n",
    "\n",
    "    if _json:\n",
    "        json_str = json.dumps(_json)\n",
    "        if json_str not in publications:\n",
    "            publications.append(json_str)\n",
    "    ##print('#######')\n",
    "publications = [json.loads(c) for c in publications]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the publications in json file.\n",
    "output_json_filename = 'liling-tan.semscholar.json'\n",
    "with open(output_json_filename, 'w') as fout:\n",
    "    json.dump(publications, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_collaborators = set(chain(*[c['Authors'].split(', ') for c in publications]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pubyears = set([c['Publication date'].split('/')[0] for c in publications])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2011', '2013', '2014', '2015', '2016', '2018', '2019'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pubyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
